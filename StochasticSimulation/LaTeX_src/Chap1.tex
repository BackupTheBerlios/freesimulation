%%%%%%%
%%%%%%% Chapter 1
%%%%%%%
\chapter{Stochastic Simulation methods}

Among the numerical techniques available to computational physics,





stochastic methods, also called Monte Carlo methods, play a 
central role. They are particularly appealing because of their 
immediacy, their power and the breadth of applications.

Monte Carlo methods rely upon the use of random 
numbers. Essentially there are two complimentary reasons to use
stochastic simulation methods:
the most obvious reason is the study of physical systems in 
which random events arise naturally; the second reason is that the 
sampling of random numbers offers an efficient numerical method 
to compute multidimensional integrals.

In order to elucidate the two important points just mentioned
we consider in the following two simple examples.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The radioactive decay}
As an example of a natural stochastic process we consider radioactive decay.
Many  heavy nuclei are intrinsically unstable and decay to 
lighter, more stable elements
under the emission of $\alpha$--, $\beta$--, or 
$\gamma$--radiation. The radioactive decay is a statistical 
process. One can not forsee at what time the next nucleous will 
decay. According to the radioactive decay law one can predict the 
mean number of nuclei, which will decay in a given time interval.
Let us denote by $\lambda$ the decay constant, i.e., the fraction 
of given nuclei decaying per second, then the average number of 
decays occurring between time $t$ and time $t+dt$ is given by the 
relation
\begin{equation}\label{DECAY_LAW}
  dn = -\lambda n dt.
\end{equation}
The quantity $dn/dt$ is called the activity. Its dimension is the 
Becquerel (1Bq = 1s$^{-1}$). To give an example, the activity of 
1g of Radium $~^{226}_{88}$Ra is approximately equal to
$3.7 \cdot 10^{10}$ Bq (In an older notation the same activity was 
named 1 Curie). $\tau=1/\lambda$ is the mean life time, during 
which the number of radioactive nuclei drops to $1/e$.

If at time $t=0$ we have $n_0$ nuclei, it follows from Eq. 
(\ref{DECAY_LAW}) that at the later time $t>0$ we are left
with
\begin{equation}\label{DECAY_NUMBER}
n(t) = n_0 \exp(-\lambda t).
\end{equation}
The half--life $t_{1/2}$ is easily evaluated from the condition
\begin{equation}\label{HALF-LIFE_1}
  n(t_{1/2}) = \frac{n_0}{2}
\end{equation}
to be
\begin{equation}\label{HALF-LIFE_2}
  t_{1/2} = \frac{\ln2}{\lambda}.
\end{equation}
It is important to remark that for each nucleus
regardless of the decay mode $\lambda$
and $\tau$ are characteristic constants which do not depend upon, 
e.g.,
the temperature, the pressure, or chemical reactions.

Let us now turn our attention to the stochastic description of 
radioactive decay from which we will derive a stochastic 
algorithm. As we have already noticed a basic ingredient of all
Monte Carlo recipes is the use of random numbers. Thus, we have to 
know how to draw random numbers in our computer program. At the 
moment it is not important for us to know how random numbers can 
be generated. This will be the subject of one of the next 
chapters. We only have to know that almost all programming
languages have a random number generator in form of some function 
in their mathematical library. Shortly we will see how this can be
achieved in Java.


Let us assume that the system is made of $N_0$ 
unstable nuclei. The probability $p$ for a nucleus to decay in the 
finite time interval $\Delta t$ is obviously given by
\begin{equation}\label{DECAY_PROB}
  p = \lambda \Delta t \;\;\;  ({\rm for} \quad \lambda \Delta t \ll 1).
\end{equation}
Therefore it is easy to decide whether a nucleus decays with 
probability $p$ or not. To do so we have to draw a random number $R$
uniformly distributed in the interval $[0,1)$. This random number 
lies with probability $p$ in the interval $[0,p\Delta t]$. 
Therefore, if $R \leq p \Delta t$ a decay takes place, 
otherwise it does not. Hence in each time step $\Delta t$ we have to 
decide between two cases:
a) If a decay takes place we put $N \longrightarrow N-1$ and 
$t \longrightarrow t+\Delta t$; b) If no decay takes place we set 
simply $t \longrightarrow t + \Delta t$.

Thus, schematically the stochastic algorithm to simulate the 
radioactive decay reads

\begin{verbatim}
For t=0 to t with step dt
    For each remaining  nucleous
        Decide if the nucleous decays
        if (random number < p dt) then
              N ---> N-1
        end
    end loop over nuclei
end loop over time
\end{verbatim}

Before wriing a progranm in Java to simulate the radioactive decay let
us briefly discuss the geration of random numbers in Java.

\subsection{Random numbers in Java}
We have already met in the Introduction different possible ways to generate
random numbers in Java. The first method  \verb|random()| we encountered 
was contained in the \verb|java.lang.Math| class.
The method \verb|random()| ccreates a single Random object the first time it
is invoked and returns pseudorandom numbers for that object for each
subsequent call. A better way to generate random numbers is provided by the
\verb|java.util| package, which contains several standard utilities
interfaces and classes. This second possibility is to be preferred since it
offers more possibilities to control the generation of random numbers. With
the help of 
\begin{verbatim}
public Random()
\end{verbatim}
we can creat a new Random object. As we will learn in the next Chapter
the sequence of random numbers begins with the so--called seed.
The class Random automatically chooses a seed according to the current time.
If a specific seed is wished, this can be fixed
with the help of \verb|public Random(long seed)|.  
Furthermore, the method \verb|public synchronized void setSeed(long seed)|
which can be invoked at any time resets the sequence of random numbers to
start from the given seed.
Having instanciated the
Random object a pseudorandom number uniformly distributed between 0.0
(inclusive) and 1.0 (exclusive) is returned by invoking 
\begin{verbatim}
public double nextDouble()
\end{verbatim} 
Similarly, the method \verb|nextFloat| may be invoked to generate uniformly
distributed random numbers of the \verb|float| type.
In later Chapters we will also need uniformly distributed integer valued 
random numbers. Such pseudorandom numbers between \verb|Integer.MIN_VALU| 
and \verb|Integer.MAX_VALUE| can be generated in Java with the
help of
\begin{verbatim}
public long nextInt()
\end{verbatim} 
Alternatively it is possible to invoke also the method \verb|nextLong()|,
which generates discrete random numbers uniformly distributed between 
\verb|LONG.MIN_VALUE| and \verb|Long.MAX_VALUE|.

For later purposes, let us mention that the package \verb|java.util| also
contains a method
\begin{verbatim}
public synchronized double nextGaussian()
\end{verbatim}
which returns a pseudorandom Gaussian--distributed double value with mean 0.0
and standard deviation 1.0.

Now we are in the position to write a Java code for the simulation of
the radioactive decay.

\subsection{The Simulation code}
The above algorithm written in Java is shown in the following listing.
\inputlisting{./Listings_Java/RadioactiveDecay.java}{RaioactiveDecay.java}


The program is straightforward. In line xy the relevant variables 
are initialized. The main loop starts is line xy. bla bla.
In order to check the results we evaluate the exact solution in 
line xy. Finally, we plot the result of the simulation and the 
exact solution of the decay law in a linear and in a 
semilogaritmic plot. 


The class is part of the \verb|simulation| package. The class
\verb|RadioactiveDecay| has been written in such a way that it can be
run as an application as well as an applet. The trick is to extend the
\verb|Applet| class and to define, as it is necessary for
applications, a \verb|main| method. The actual algorithm is
implemented in lines xx to yy. In lines xx to yy we compute the exact
analytical solution. Finalyy we print out the results of the
simulation in the loop beginning at lines xxx. The output of the 
simulation is printed on the commando line.

We are now in the position to perform a simulation. To this end we
run the program with the following parameters
\begin{eqnarray*}
N_0 = 1000; \quad \lambda= 0.02 s^{-1}; \quad \Delta t = 1s; \quad 
 \verb|t_end| = 300s.
\end{eqnarray*}


Running the program it is evident that the screen outout is not particularly
satisfactory to examine the reults of the simulation. Thus, we have reached
the point where we feel the necessity to learn something about the graphical
possibilities of Java.


\subsection{A very easy plot}

Before trying to plot the data generated with the program
\verb|RadoactiveDecay| we want to discuss the most simple Java code which
allows to plot some 2 dimensional data. With the help of this example we will
learn the foundations of the graphical tools of Java. The code we want to
discuss is the \verb|PlotEasy.java| class which can be run as an applet or as
an application.

\inputlisting{./Listings_Java/PlotEasy.java}

As we can see the code begins by importing packages. we already met the first
one, the \verb|java.applet.Applet| package in the applet version of the
HelloWorld program. The \verb|java.applet| package is a small package. It
simply contains the \verb|Applet| class, which is the superclass of all
applets, i.e., in order to create your own applet you have to creat a subclass
of this class and override some or all of its methods (see Chap. 0). The
second package we have to import is the \verb|java.awt| package, where 
\verb|awt| stands for the Abstarct Window Toolkit. An important class of this
package is the \verb|java.awt.Graphics| class, which encapsulates most of the
graphics functionality of the Java API. Instances of this class represent a
"graphical context" in which we can perform graphical operations. 

In order to understand the deep relation bewteen applets and the AWT it is
instructive to look at the following figure which shows the inheritance
hierarchies of the Applet class.

\begin{figure}
\label{hierarchyapplet}
\caption{This figure shows the inheritance hierarchy of the Applet class.}
\end{figure}

Applets inherit the drawing and event handling methods from the AWT
\verb|Components| class. \verb|Component| is the superclass of all GUI
components in the \verb|java.awt| package. Components defines many methods.

The \verb|java.awt.Container| class implements a component that contains other
components. \verb|Container| can not be instantiated directly. You always have
to use one of its subclasses, such as \verb|Panel|, \verb|Frame| or
\verb|Dialog|. Once a \verb|Container| is created you can set its Layout
Manager with \verb|setLayout()| or add componets to it with \verb|add()|.
You can remove components with \verb|remove()|. 

The \verb|java.awt.Panel| class is a Container that s itself contained in a
Container. It does not create a separate window of its own. Applets are a
subclass of \verb|Panel| that is contained within a Web browser or an applet
viewer. The following figure shows the hierarchy relations of some (not all!)
components and layout classes of the \verb|java.awt| package.

\begin{figure}
\label{awthierarchy}
\caption{The hierarchy of the awt package.}
\end{figure}

Now we have the necessary background to understand what is going on in the
\verb|PlotEasy.java| program. The class \verb|Ploteasy| extends the 
\verb|Applet| class and has a main method. In the \verb<main< method we
instantiate the \verb|Applet| \verb|PlotEasy|  and the \verb|Frame| \verb|f|.
The hierarchy of the \verb|Frame| class is (see Fig. \ref{awthierarchy})
Object $\rightarrow$ Component $\rightarrow$ Container $\rightarrow$ Window
$\rightarrow$ Frame. The \verb|Frame| class represents an optionally resizable
application window with a title bar. Wit the help of the method \verb|add|,
das ich nicht ganz verstehe wird dann ...... !!!!!!!!!!!

With the help of the method \verb|setSize(int width, int height)| we fix the
dimensions of the frame (in pixels). The \verb|show()| method displays the
frame. As we already know \verb|a.init()| stars the applet.

In principle the part of the code we just described is not necessary. we
included it only to allow the plot to be resizable. Try to run the code
without the lines !! to !!

The actual plotting is performed by the \verb|paint()| method which is draws
on the screen. Applets typically override some of the methods of the
\verb|java.awt.Component|. The simplest way for a Component to draw itself is
to put drwaing code in the \verb|paint()| method. In lines !! to !! we see a
simple example of implementing the \verb|paint()| method. The \verb|Graphics|
class defines methods for drawing different kinds of shapes. The method wich
we use here is the
\begin{verbatim}
drawline(int x1, int y1, int x2, int y2)
\end{verbatim} 
method, which simply draws a line in the \verb|Graphics| object \verb|g|
current color. Other typical methods are, e.g., 
\verb|drawRect()| and \verb|fillRect()| to draw and fill with the current
color rectangls, \verb|drawArc()| and \verb|fillArc| to draw and fill arcs,
\verb|drawPolygon(int[] xPoints, int[] ypoints, int npoints| and 
\verb|fillPolygon()| to draw polygons.

The  method \verb|getsize().height| and \verb|getSize().width|, which we use
in lines !! and !! return the height and the width of the Frame.
Now that we understand the code let us run the program.


\inputlisting{./Listings_Java/PlotEasy.java}

Having learned the basic graphical tools of the AWT with the help of
the easiest plot program, we can now apply what we have just learned
to the simulation of the radioactive decay.

\inputlisting{./Listings_Java/RadioactiveDecay_easyplot.java}

To implement the graphical facilities in the
\verb|RadioactiveDecay.java| code is easy. We immediatekly recognize
inthe lines xx -- yy the \verb|paint()| method. The results of the
simulation have to be scaled appropriately to fit in the Frame. The
curve is plotted with the method \verb|drawLine()|. Since we want to
plot also the exact analytical solution for the mean values in red we
set
\begin{verbatim}
g.setcolr(Color.red)
\end{verbatim}
in line xy before drawing the corresponding curve.

It is important to note that in the lines xx--yy we have added the
code
\begin{verbatim}
frame.WindowListener()
\end{verbatim}
which allows to handle the request to close the window.

\subsection{Ptplot}
The quality of the plot of the simulation results are rather poor
compared to high standards we are used to today. It is clear, that we
could now go on refining the plot with the help of the Java
AWT. Although this might be an intersting and instructive task, it is
not our primary interest in this book. Fortunately, there are advanced
``D graphics components wghich can be used in applets and
applications. One of these package is Ptplot (you pronounce it
pee--tee--plot). The Ptplot package is released under the liberal UC
Berkley copyright. It has been developed by edward A. Lee, C. Hylands,
and W. Wu. You are free to download it at
http://ptolemy.eecs.berkely.edu/java/ptplot.html where you also find
the documentation and many demos of Ptplot. The components of Ptplot
have the following properties:
\begin{itemize}
\item it is embaddable in applets and applications
\item you may use binary or ascii data
\item the plots are auto--ranging
\item you may label automatically or manually the axes
\item logarithmic axes
\item live, animated plots
\item infinite zooming
\item  various plot styles (coonnected lines, scatter plots, bars, ..)
\item various point styles (none, dots, points, ....)
\item multiple data sets and legends
\item color or black and white plots
\item error bars.
\end{itemize}
Before writing the the first code using Ptplot let us look at the
class hierarchy of Ptplot:

\begin{figure}
\caption{The class hierarchy of Ptplot.}
\end{figure}

Let us now a very simple program in order to show what you need to
invoke the Ptplot methods.

\inputlisting{./Listings_Java/ptplot_Demo.java}

We se that we have to import additionally the  ptplot package. The
class \verb|ptplot_Demo| extends the class \verb|PlotApplet|. Again we
want to run the code as applet as well as an application so the class
does have a main method. In lines xx --yy we instantiate the new Frame
and activate the WindowListener as we did it in the
\verb|RadioactiveDecay_ploteasy.java| code. The actual plot routines
arein lines xx to yy. In the \verb|init()| method we invoke the method
\verb|super.newPlot(9| to create a new plot, \verb|super.init()| to
initialize it and \verb|plot().setTitle| to give the plot a title.

The output of the code can be seen in Fig. (\ref{}). 

Next we want to draw the results of the simulation of the radioactive
decay process with the help of Ptplot and learn at the same time how
to exploit the features of Ptplot. The corresponding code can be seen
below.


\inputlisting{./Listings_Java/RadioactiveDecay_ptplot.java}

The actual plotting code starts in lines xx and ends in lines
yy. There we use several methods of the \verb|ptplot.Plot|
class. Allmethods are called \verb|setMethods| where \verb|Method| is
selfexplaining. Several other methods are implemented in the
\verb|Ptplot.Plot| class and  are summarized in the following table. 




\subsection{The results of the simulation}

The results of the simulation are plotted in Fig. (\ref{FIG_DECAYA}) and 
(\ref{FIG_DECAYB}).
\begin{figure}
\label{FIG_DECAYA}
\includegraphics[width=10cm]{f_decaya.eps}
\caption{A realization of the stochastic process of radioactive decay.
The parameters of the simulation were $N_0 = 100; 
\quad p = 0.01 s^{-1}; \quad \Delta t = 1s;  \quad tend = 300s$}
\end{figure}
\begin{figure}
\label{FIG_DECAYB}
\includegraphics[width=10cm]{f_decayb.eps}
\caption{A realization of the stochastic process of radioactive decay.
The parameters of the simulation were $N_0 = 1000; 
\quad p = 0.03 s^{-1}; \quad \Delta t = 1s;  \quad tend = 100s$}
\end{figure}
 It is 
immediately recognized that the simulation results fluctuate around 
the expected curve. This is of course not astonishing since the 
exact result holds for mean values. In order to achieve a better
agreement with the decay law it is necessary to run the simulation
several times and to take the average over the different 
realizations of the decay process. This can easily be achieved by 
a simple modification of the program {\sf decay}. We 
introduce an additional input variable, the number of realizations
{\sf nreal} and accordingly implement a loop over the different 
realizations. This can be best seen in the listing of the 
new program {\sf decayr}.


At the end of the realizations loop
we have to perform the average. This is seen in lines xy.
(STRESS MORE THE IDEA OF REALIZATIONS!!!!; allgemeine Strategie erlaeutern.)

Note that in order to speed up the program we have modified slightly 
the algorithm  so that we can save a loop.
The probability to observe one decay in time $\Delta t$ is
\begin{equation}
p = \beta \Delta t
\end{equation}
where $\beta = \lambda N$ and $\Delta t$ must be small enough so 
that $\beta \delta t \ll 1$. 
From the elementary rules of combinatorics we know that
the probability to observe $n$ decays in time $t=m\Delta t$ is therefore
given by
\begin{equation}
P = p^n(1-p)^{m-n} {m \choose n}.
\end{equation}
Inserting the definition of $p$ the above expression can be cast 
in the form
\begin{equation}
P = \left( \frac{\beta t}{m}\right)^n 
     \left( \frac{1 - \beta t}{m} \right)^{m-n}
      \frac{m!}{(m-n)! n!}.
\end{equation}
Performing the limit $\Delta t \longrightarrow 0$ (i.e. $m 
\longrightarrow \infty$) and considering that
\begin{equation}
\left(1-  \frac{\beta t}{m} \right)^{m} \longrightarrow 
            \exp(-\beta t),
\end{equation}
\begin{equation}
\left( 1- \frac{ \beta t}{m} \right)^{-n} \longrightarrow 
            1,
\end{equation}
and
\begin{equation}
\frac{m!}{(m-n)! n!} \longrightarrow m^n
\end{equation}
we obtain the result
\begin{equation}
P = \frac{\mu^n \exp(-\mu)}{n!},
\end{equation}
where $\mu = \beta t$. The above distribution is the well know
Poisson distribution.

It is now easy to verify that the number of decays in a given 
interval is distributed according to the Poisson distribution.
To this end we have counted the number of decays in a given 
interval. This is accomplished in the lines xy. At the end of the
program we plot in a histogram the distribution of the number of 
decays and overlay the expected Poisson
distribution.  This is achieved in the program {\sf decayr} with the 
help of the {\sf hold} command. When you set "{\sf hold on}" MATLAB does not 
remove the existing graph; the following data are addeded to the 
current graph. The overplotting of data is terminated by 
setting "{\sf hold off}".

\subsubsection{Listing of the program decayr}
\inputlisting{./Listings/decayr.m}


Run the program for the following two sets of parameters:
\begin{eqnarray*}
N_0= 100, p = 0.001 s^{-1}, \Delta t = 1s, t = 100s \\
N_0= 100, p = 0.0001 s^{-1}, \Delta t = 1s, t = 100s
\end{eqnarray*}
with nreal = 100 and nreal = 1000.

The result of  two simulations can be seen in figs. x and y.
\begin{figure}
\includegraphics[width=\textwidth]{f_decay1.eps}
\caption{The distribution of the number of decays computed with 
the program decayr. 100 realizations. The simulation was run for
N0=100 and lambda=0.001.}
\end{figure}

\begin{figure}
\includegraphics[width=\textwidth]{f_decay2.eps}
\caption{The distribution of the number of decays computed with 
the program decayr. 1000 realizations. The simulation was run
for N0=100 and lambda = 0.001.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simple Monte Carlo evaluation of integrals}
It is the purpose of this subsection to introduce Monte Carlo Methods
in the context of the numerical evaluation of definite integrals.
We will see in later chapters that Monte Carlo integration is the
method of choice when treating multidimensional
integrals numerically. As a typical rule of thumb
``classical'' deterministic methods are outperformed
by Monte Carlo methods  for systems with a large number of 
degrees of freedom.
For simplicity and to stress the basic ideas 
it is convenient at the moment to consider one--dimensional definite
integrals of the form
\begin{equation}
\label{INTEGRAL}
I = \int_a^b dx f(x).
\end{equation}
Obviously such integrals can be evaluated analytically for many
integrands
$f(x)$.  However, there are as well many cases for which a numerical
evaluation is necessary.

Before introducing the Monte Carlo approach to numerical integration
let us remind the basic ``classical'' deterministic approach to
numerical integration. The standard approach is based upon the
geometrical interpretation of the integral (\ref{INTEGRAL}) as the
area under the curve of the function $f(x)$ between the points $a$ and
$b$. In the simplest algorithm this area (see figure) is approximated
as a sum over rectangles. To this end the $x$--axis is divided into
$n$ equally spaced intervals of width $\Delta x$,
\begin{equation}
\Delta x = \frac{b-a}{n}
\end{equation}
whose ends are given by
\begin{equation}
x_i = x_0 + i\Delta x
\end{equation}
for $i=1, \ldots ,n$. Of course, $x_0 = a$ and $x_n =b$. Thus in the
so--called rectangular approximation the integral is evaluated as
\begin{equation}
\label{I_CLASSICAL}
I_n = \Delta x \sum_{i=0}^{n-1} f(x_i).
\end{equation}
Of course, other more accurate approximations are possible.

How can we now evaluate the above integral by drawing random numbers?
The standard way is based on a very simple idea. 
From the introductory course in analysis we know that the Mean 
Value Theorem states that the exact value of the integral $I$ is 
given by
\begin{equation}
I= (b-a) f(\zeta)
\end{equation}
for some value of $\zeta$ in the interval $a \le \zeta \le b$. $f(\zeta)$
represents the average value of the function $f(x)$ 
in the interval $[a,b]$. Thus we could also write
\begin{equation}
I = (b-a) \langle f \rangle,
\end{equation}
where $\langle  \rangle$ denotes the mean value.
Let us draw $n$
random numbers which are uniformly distributed in the interval $[a,b]$
and let us sample the corresponding value of $f(x_i)=f_i$. The Monte Carlo
estimate $I_n$ of the integral $I$ is then the sample mean, which is
given by
\begin{equation}
\label{MCI_STANDARD}
I_n = \frac{(b-a)}{n} \sum_{i=1}^{n} f(x_i),
\end{equation}
where $n$ is the number of trials. Amazingly the form of the above
estimate is very similar to the classical formula (\ref{I_CLASSICAL}).
The fundamental difference is that now the $n$ points at which the
function $f$ is evaluated are no longer equally spaced but randomly 
distributed.

There is also the possibility to compute the integral $I$
stochastically
with the help of the ``Hit or Miss'' algorithm. The idea behind
this algorithm is again very simple. To be explicit we imagine a rectangle
of height $h$ and width $(b-a)$ such that the function $f(x)$ lies
within the rectangle (see figure; Gould, p.329). To evaluate the
integral we draw randomly pairs of uniformly distributed random
numbers $(x_i,y_i)$ such that $a \le x_i \le b$ and $0 \le y_i \le h$.
In other words the probability to draw a point within the rectangle is
given by the inverse of the area $A$ of the rectangle,
i.e. $1/(b-a)h$. It is now evident how the area under the
function $f$ may be estimated. The fraction of points $(x_i,y_i)$
which satisfy the condition $y_i \le f(x_i)$ is an estimate of the
ratio of the integral $I$ to the area $A$ of the rectangle. Hence,
drawing $n$ random pairs the estimate $I_n$ of $I$ by this ``scoring''
method is given by
\begin{equation}
I_n = A \frac{n_s}{n},
\end{equation}
where $n_s$ is the number of ``hits'', i.e., of points lying below the
curve $f(x)$.

Before writing two simple programs to elucidate the above algorithms
it is important to have in mind that both estimates are affected by
statistical errors. Let us consider for simplicity 
the standard method. Since the $f(x_i)$ are random we know 
from the elementary theory of data analysis
that an appropriate measure of the error is given by the variance
which is defined by
\begin{equation}
{\rm Var}(f) = \langle f^2 \rangle - \langle f \rangle^2.
= \langle (f -\langle f \rangle)^2 \rangle
\end{equation}
Since we draw a finite number of random numbers we can
estimate the mean value by using
\begin{equation}
\hat{f}  = \frac{1}{n} \sum_{i=1}^n f(x_i) 
\end{equation}
and correspondingly the estimate of the variance by using
\begin{equation}
{\rm Var}(f(x_1),\ldots, f(x_n)) = \frac{1}{n-1} \sum_{i=1}^n 
   (f(x_i)- \hat{f})^2 = \sigma_f^2.
\end{equation}
The quantity $\sigma_f = \sqrt{{\rm Var}(f_1, \ldots, f_n)}$ 
is also called the standard deviation. In the previous expression
we have used the short--hand
notation $f(x_i) = f_i$. However,
we are not interested in the error of $f$ but in the error of the
estimate $I_n$ which is a sum over random numbers. 

Repeating the 
simulation and hence drawing other random numbers we will get another
estimate of $I_n$. Therefore, repeating the simulation $m$ times 
we can estimate the mean of $I_n$ as
\begin{equation}
\hat{I_n} = \frac{1}{m} \sum_j^m I_n(j)
\end{equation}
and the corresponding variance as
\begin{equation}
{\rm Var}(I_n(1), \ldots, I_n(m)) = 
\frac{1}{m-1} \sum_j^m (I_n(j) - \hat{I_n})^2 = \sigma_I^2
\end{equation}
We will denote the above variance also by $\sigma_I^2$.
Of course, proceeding this way is not very practical since we
have to perform the simulation $m$ times. A much more economical
estimation of the error of the mean of $I_n$ could be achieved by 
establishing a simple relation between $\sigma_I$ and the standard 
deviation of the individual trials $\sigma_f$. To this end we 
introduce the discrepancy $\delta f_i$ between the
individual trial $f_i$ and its mean $\langle f \rangle$. The 
discrepancy $\delta I_n$ between $I_n$ and its mean value can be
obtained to first order in the $\delta f_i$ by a simple Taylor 
expansion (error propagation rules)
\begin{equation}
\delta I_n = \sum_{i=1}^n \frac{\partial I_n}{\partial f_i} \delta 
f_i.
\end{equation}
Hence, it follows from the above equation by taking the average over
$\delta I_n^2$ that
\begin{equation}
\langle \delta I_n^2 \rangle = \sum_{i,j=1}^{n}
    \frac{\partial^2 I_n}{\partial f_i \partial f_j} 
     \langle \delta f_i \delta f_j \rangle.
\end{equation}
It is plausible to assume, that 
$\langle \delta f_i \rangle = 0$
for all $i$ and that the $\delta f_i$ are not correlated
for $i \neq j$, i.e.,
$\langle \delta f_i \delta f_j \rangle = \langle f_i \rangle \langle f_j \rangle$
and that for $i=j$ we have $\langle \delta f_i^2 \rangle = \sigma_f$ 
for all $i$ it follows from the above equation that
\begin{equation}
\sigma_I^2 = \sum_{i=1}^n \left(
      \frac{\partial I_n}{\partial f_i} \right)^2 \sigma_f^2
      = \frac{1}{n^2} n \sigma_f^2 = \frac{\sigma_f^2}{n}
\end{equation}
and finally we have the useful relation
\begin{equation}
\
sigma_I = \frac{\sigma_f}{\sqrt{n}}.
\end{equation}
The mean error of the mean scale with 1 over the square root of 
the number of individual trials. The precision of the estimate 
thus increases only slowly with the number of trials (remark: central
limit theorem: see Chapter 2).

Now we are in the position to write two programs to implement the above
stochastic algorithms. In order to be specific we compute the integral
\begin{equation}
I = \int_0^1 dx \sqrt{1-x^2} = \frac{\pi}{4}.
\end{equation}
In other words we want to estimate the number $\pi$ by Monte Carlo
methods.

We begin by the standard method. The listing of an according 
program can be seen below.

\subsubsection{Listing of the program mcpi.}
\inputlisting{./Listings/mcpi.m}

We run the program for $n=10, 100, 1000, 10000$. The result of the 
four simulations can be seen in Fig. xy.
\begin{figure}
\includegraphics[width=\textwidth]{plotmcpi.eps}
\caption{The estimation of pi for n=10,100,1000,10000. The 
error bars correspond to the standard deviation of the mean of the 
estimate.}
\end{figure}

Next we write a program for the scoring  method. 

\subsubsection{Listing of the program mcpiscore.m}
\inputlisting{./Listings/mcpiscore.m}

Again we run the simulation for n=10, 100, 1000, 10000.
The result of a simulation can be seen in the next Figure.
\begin{figure}
\begin{center}
\includegraphics[width=.7\textwidth]{fmcpiscore.eps}
\end{center}
\caption{The scoring method. The continuous line represents
the function $\sqrt{(1-x^2)}$.}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Beyond this chapter}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises}

Use the  Matlab function \texttt{rand()}
to solve the following problems (don´t care about the quality and
the algorithm of the random number genrator, for now):

\begin{Ex}
\label{Photoabsorption}
\textbf{Photoabsorption \cite[]{reif:67}} \\
Consider the absorption of photons passing through a gas in two dimensions.
We model the gas by introducing slabs of width $dx$ and density $n$ (in
particles per area), which absorb the incident photons. The slab
particles have a cross-sectional area of $\sigma$.

So the probability of a photon to be absorbed in the slab will be
($M$ is the number of particles in the slab of the heigth $dy$)
$$ P(\text{Photon absorbed}) = \frac{M\sigma}{dy} =
      \frac{\sigma n dx dy}{dy} = \sigma n dx  \quad .$$
We have assumed that there is no overlap between the cross-sections of
the slab particles.

Write a program to simulate this process on the computer. Take $N$
incident photons and watch the number of particles left over
against the slabs passed in a diagram. Do this simulation several
times and calculate the ensemble-average. What process you know
is similar to this behaviour and what takes the place of the spatial
dimension in that case?

%If we now have N identical slabs in a row, the probability of passing
%through all the slabs would be $(1-p)^N$, if the transmissions
%are statistically independent of each other.
%Then for a slab of finite thickness $X=N dx$ with $N\to\infty$, we
%get the Transmission probability
%$$ P(\text{transmitted through $N$ slabs}) =
%       \left(1-\frac{n\sigmaX}{N}\right)^N \quad .$$

%Now simulate the following systems:
%identical photons are absorbed in one slab ($N$ slabs)
\end{Ex}

\begin{Ex}
\label{Monte-Carlo_Integration}
\textbf{Monte-Carlo Integration -- Speed and Accuracy} \\
Write a program for the calculation of the following integral:
$$ \int_0^1 \frac{1}{1+x^2} dx\quad .$$
\begin{enumerate}
\item using the hit and miss method
\item using the standard method
\end{enumerate}
For both algorithms, calculate the mean and the standard deviation
as discussed in the lecture. Also use the analytical result of the
integral to calculate $\pi$. Compare the accuracy of both algorithms
using the approximations of $\pi$. Compare the speed of the two
programs by using the \texttt{cputime} function in Matlab.
(e.g. type the following to time the random number generator:
\texttt{t=cputime;x=rand(1000);cputime-t})

To that end, create a table and a plot with the two parameters
($n$: the number of intervals and $N$: the number of realizations)
against
the accuracy (use at least 5 values). To save time, you can first
check for a good $n$  and then do the plots only against $N$.
For the speed, plot the cputime against the achieved accuracy for
many different $N$.
\end{Ex}

\begin{Ex}
\label{Euler_Constant}
\textbf{Euler´s Constant using Monte-Carlo Algorithm %
          \cite[]{mohazzabi:98}} \\
Suppose throwing $N$ darts randomly at a dart board, which has been
divided into $R$ equal size regions. The probability of hitting one region
is $p=1/R$. Then the probability of hitting an empty region
(not already occupied by a dart) is $(1-p)^N$. Using the binomial
distribution, you can get the probability for hitting a region with
$m$ darts. If you choose
the number of regions equal to the number of darts
thrown on the board, we have $p=1/N$ and therefore
$$ P(\text{hitting an empty region}) = \left( 1-\frac{1}{N} \right)^N\quad .$$

Because the above series converges to $e$ for $N\to\infty$, we can use
the following method to get an approximation of the Euler constant:
\begin{enumerate}
\item[(i)] Throw randomly a large number of darts (say $N$) on a board, which has
  been divided into $N$ equal size regions.
\item[(ii)] Count the number of empty regions (call it $N_0$).
\item[(iii)] The fraction $N/N_0$ is a good estimate of the Euler constant $e$.
\end{enumerate}

Write a program for that algorithm and check the results. You can even
use $N/N_1$, if $N_1$ is the number of regions with the occupancy of
one dart. Check this, too. What $N$ do you need to
get the same accuracy using the formula? And how many terms of the
series for $e$ ($\sum_{i=0}^\infty 1/i! = e$)?
\end{Ex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{peter}
\bibliography{V_98,simulit}
